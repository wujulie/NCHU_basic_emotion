{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Evaluate.ipynb","provenance":[],"mount_file_id":"1CVIoJYiQe1n0thjxFguRE7t3frP6N21L","authorship_tag":"ABX9TyNzpGNauLkeqMYBUmq09eUX"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"u1jLUx65CeAu","executionInfo":{"status":"ok","timestamp":1611800117649,"user_tz":-480,"elapsed":1226,"user":{"displayName":"吳貞宜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIOzgYhbporG1Eax-zD0HNdC2UZr8CRTfHsZcY5g=s64","userId":"00889427696288622203"}}},"source":["# from Package.Data import Data, DataType, Evaluate\r\n","# from Package.Model import *\r\n","# from Package.Trainer import *\r\n","\r\n"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZfS31Vx5knER"},"source":["Data.py 資料"]},{"cell_type":"code","metadata":{"id":"k4bbikXRjz_6","executionInfo":{"status":"ok","timestamp":1611800121738,"user_tz":-480,"elapsed":5310,"user":{"displayName":"吳貞宜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIOzgYhbporG1Eax-zD0HNdC2UZr8CRTfHsZcY5g=s64","userId":"00889427696288622203"}}},"source":["import itertools\r\n","\r\n","import cv2\r\n","import dlib\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import pandas as pd\r\n","import time\r\n","from keras.preprocessing.image import ImageDataGenerator\r\n","from keras.utils import np_utils\r\n","from sklearn.model_selection import train_test_split\r\n","from sklearn.metrics import confusion_matrix\r\n","from sklearn.preprocessing import StandardScaler\r\n","from enum import Enum\r\n","# 輸入資料型態\r\n","from sklearn.utils import shuffle\r\n","import os\r\n","# 資料類別\r\n","class DataType(Enum):\r\n","    ALL_DATA = 'all data'       # 所有資料\r\n","    TRAIN = 'train data'        # 只有訓練資料\r\n","    TEST = 'test data'          # 只有測試資料\r\n","    CUSTOM = 'custom data'      # 原先設計好之資料\r\n","    SMALL = 'small dataset'     # 小型資料集\r\n","\r\n","# 輸入資料\r\n","class Data(object):\r\n","    def __init__(self, data_type=DataType.ALL_DATA,\r\n","                 img_width=224, img_height=224,\r\n","                 split_data=False, filename='small_data', num_classes=7,#訓練時須修改標籤數目\r\n","                 data_generator=True):\r\n","        print(\"- create data instance\")\r\n","        try:\r\n","            print(\"\\t- set data type ... \", end=\"\")\r\n","            self.data_type=data_type\r\n","            self.num_classes=num_classes\r\n","            self.filename = filename\r\n","            print(\"{}\".format(data_type.name))\r\n","        except:\r\n","            print(\"\")\r\n","        try:\r\n","            print('\\t- set X and Y ... ', end=\"\")\r\n","            self.x = np.load('/content/drive/MyDrive/basic_emotion/' + filename + '_x.npy')\r\n","            self.y = np.load('/content/drive/MyDrive/basic_emotion/' + filename + '_y.npy')\r\n","            print(\"OK\")\r\n","        except  Exception as e:\r\n","            print(e)\r\n","        try:\r\n","            print(\"\\t- set image shape ... \", end=\"\")\r\n","            self.img_width=img_width\r\n","            self.img_height=img_height\r\n","            print(\"OK\")\r\n","        except Exception as e:\r\n","            print(\"image shape setting error\")\r\n","            print(e)\r\n","        self.split_data=split_data\r\n","        try:\r\n","            print(\"\\t- start data pre process ... \", end=\"\")\r\n","            self.data_generator = data_generator\r\n","            self.pre_process()\r\n","            print(\"OK\")\r\n","        except  Exception as e:\r\n","            print(\"error\")\r\n","            print(e)\r\n","\r\n","\r\n","    # 資料預處理\r\n","    def pre_process(self, test_size=0.2, val_size=0.1, filename=None):\r\n","        x, y = shuffle(self.x, self.y)\r\n","        x = x.reshape(x.shape[0], self.img_width, self.img_height, 1)\r\n","        if (self.data_type == DataType.ALL_DATA):\r\n","            train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=test_size, random_state=25)\r\n","            train_x, val_x, train_y, val_y = train_test_split(x, y, test_size=val_size, random_state=25)\r\n","        if (self.data_type == DataType.TRAIN):\r\n","            train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=test_size, random_state=25)\r\n","            val_x = test_x\r\n","            val_y = test_y\r\n","        if (self.data_type == DataType.TEST or self.data_type == DataType.SMALL):\r\n","            train_x = x\r\n","            train_y = y\r\n","            test_x = x\r\n","            test_y = y\r\n","            val_x = x\r\n","            val_y = y\r\n","\r\n","        if (self.data_type == DataType.CUSTOM):\r\n","            self.train_x = self.arr_reshape(x)\r\n","            self.train_y = y\r\n","            self.test_x, self.test_y = shuffle(np.load('/content/drive/MyDrive/basic_emotion/{}_test_x.npy'.format(filename)), np.load('/content/drive/MyDrive/basic_emotion/{}_test_y.npy'.format(filename)))\r\n","            self.val_x, self.val_y = shuffle(np.load('/content/drive/MyDrive/basic_emotion/{}_val_x.npy'.format(filename)), np.load('/content/drive/MyDrive/basic_emotion/{}_val_y.npy'.format(filename)))\r\n","            self.test_x = self.arr_reshape(self.test_x)\r\n","            self.val_x = self.arr_reshape(self.val_x)\r\n","\r\n","        self.train_x = train_x\r\n","        self.train_y = train_y\r\n","        self.val_x = val_x\r\n","        self.val_y = val_y\r\n","        self.test_x = test_x\r\n","        self.test_y = test_y\r\n","        self.one_hot_encoding()\r\n","        self.save_data()\r\n","\r\n","    # 對輸出值進行 one hot encodcing\r\n","    def one_hot_encoding(self):\r\n","        try:\r\n","            pass\r\n","            self.train_y = np_utils.to_categorical(self.train_y, self.num_classes).astype('int')\r\n","            self.test_y = np_utils.to_categorical(self.test_y, self.num_classes).astype('int')\r\n","            self.val_y = np_utils.to_categorical(self.val_y, self.num_classes).astype('int')\r\n","        except  Exception as e:\r\n","            print(e)\r\n","\r\n","    # 對 numpy 進行矩陣重組\r\n","    def arr_reshape(self, arr):\r\n","        return arr.reshape(arr.shape[0], self.img_width, self.img_height, 1)\r\n","\r\n","    # 靜態取用矩陣重組\r\n","    @classmethod\r\n","    def static_arr_reshape(self, arr, img_width=224, img_height=224):\r\n","        return arr.reshape(arr.shape[0], img_width, img_height, 1)\r\n","\r\n","    # 靜態取用 one hot encoding\r\n","    @classmethod\r\n","    def static_one_hot_encoding(self, y=None, classes=6):\r\n","        return np_utils.to_categorical(y, classes).astype('int')\r\n","\r\n","    # 資料擴增\r\n","    def generator(self, batch_size):\r\n","        # train_datagen = ImageDataGenerator(horizontal_flip=True, rotation_range=10, zoom_range=0.2)\r\n","        # train_datagen = ImageDataGenerator(horizontal_flip=True, rotation_range=10)\r\n","        if self.data_generator:\r\n","            train_datagen = ImageDataGenerator(horizontal_flip=True, rotation_range=10, zoom_range=0.2)\r\n","            # train_datagen = ImageDataGenerator(horizontal_flip=True, rotation_range=10)\r\n","            train_datagen.fit(self.train_x)\r\n","            train_generator = train_datagen.flow(self.train_x, self.train_y, batch_size=batch_size)\r\n","            return train_generator\r\n","        else:\r\n","            train_datagen = ImageDataGenerator()\r\n","            train_datagen.fit(self.train_x)\r\n","            train_generator = train_datagen.flow(self.train_x, self.train_y, batch_size=batch_size)\r\n","            return train_generator\r\n","\r\n","    # 資料儲存\r\n","    def save_data(self):\r\n","        np.save('/content/drive/MyDrive/basic_emotion/' + self.filename + '_train_x.npy', self.train_x)#10/13改過\r\n","        np.save('/content/drive/MyDrive/basic_emotion/' + self.filename + '_train_y.npy', self.train_y)\r\n","        np.save('/content/drive/MyDrive/basic_emotion/' + self.filename + '_val_x.npy', self.val_x)\r\n","        np.save('/content/drive/MyDrive/basic_emotion/' + self.filename + '_val_y.npy', self.val_y)\r\n","        np.save('/content/drive/MyDrive/basic_emotion/' + self.filename + '_test_x.npy', self.test_x)\r\n","        np.save('/content/drive/MyDrive/basic_emotion/' + self.filename + '_test_y.npy', self.test_y)\r\n","\r\n","    # 將圖片轉換成矩陣\r\n","    @classmethod\r\n","    def load_data(self, path='', filename=''):\r\n","        folders, x, y= [], [], []\r\n","        for root, dirs, files in os.walk(path, topdown=False):\r\n","            for name in dirs:\r\n","                folders.append(name)\r\n","        folders = folders[-7:]\r\n","        start_time = time.time()\r\n","        count = 0\r\n","        for fld in folders:\r\n","            index = folders.index(fld)\r\n","            for root, dirs, files in os.walk(path + '\\\\' + fld, topdown=False):\r\n","                for file in files:\r\n","                    filepath = root + '\\\\' + file\r\n","                    img = cv2.imread(filepath)\r\n","                    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\r\n","                    resized = cv2.resize(img, (224, 224), cv2.INTER_LANCZOS4)\r\n","                    y.append(index)\r\n","                    x.append(resized)\r\n","        np.save('{}_X.npy'.format(filename), x)\r\n","        np.save('{}_Y.npy'.format(filename), y)\r\n","\r\n","\r\n","\r\n","    # 預測圖片轉換矩陣\r\n","    @classmethod\r\n","    def load_train_data(self, path=\"D:\\\\NianXiang_File\\\\CNN\\\\Dataset\\\\small_dataset\\\\NEW\", filename=\"\"):\r\n","        x = []\r\n","        y = []\r\n","        folders = []\r\n","        for root, dirs, files in os.walk(path, topdown=False):\r\n","            for name in dirs:\r\n","                folders.append(name)\r\n","        folders = folders[-7:]\r\n","        start_time = time.time()\r\n","        count = 0\r\n","        for fld in folders:\r\n","            index = folders.index(fld)\r\n","            print('Loading {} files (Index: {})'.format(fld, index))\r\n","            for root, dirs, files in os.walk(path + '\\\\' + fld, topdown=False):\r\n","                for file in files:\r\n","                    print(file)\r\n","                    if (file == '1.jpg'):\r\n","                        pass\r\n","                    else:\r\n","                        filepath = root + '\\\\' + file\r\n","                        img = cv2.imread(filepath)\r\n","                        try:\r\n","                            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\r\n","                            resized = cv2.resize(img, (224, 224), cv2.INTER_LANCZOS4)\r\n","                            y.append(index)\r\n","                            x.append(resized)\r\n","                            count = count + 1\r\n","                        except:\r\n","                            pass\r\n","\r\n","                            # file = Data.static_load_image(ffile)\r\n","        np.save('{}_x.npy'.format(filename), x)\r\n","        np.save('{}_y.npy'.format(filename), y)\r\n","        print(\"Complete\")\r\n","    # 預測圖片轉換矩陣\r\n","    @classmethod\r\n","    def load_predict_data(self, path=\"\", filename=\"\"):\r\n","        x = []\r\n","        for root, dirs, files in os.walk(path, topdown=False):\r\n","            for file in files:\r\n","                filepath = root + '\\\\' + file\r\n","                img = cv2.imread(filepath)\r\n","                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\r\n","                resized = cv2.resize(img, (224, 224), cv2.INTER_LANCZOS4)\r\n","                x.append(resized)\r\n","        np.save('{}_predict_X.npy'.format(filename), x)\r\n","    # 將圖片抓取臉部後轉換成矩陣\r\n","    @classmethod\r\n","    def get_data_from_path(self, path='D:\\\\NianXiang_File\\\\CNN\\\\Dataset\\\\LE', file_name='BE'):\r\n","        # data = np.load('predict_y_nor.npy')\r\n","        output = {}\r\n","        x = []\r\n","        y = []\r\n","        folders = []\r\n","        for root, dirs, files in os.walk(path, topdown=False):\r\n","            for name in dirs:\r\n","                folders.append(name)\r\n","        folders = folders[-7:]\r\n","        start_time = time.time()\r\n","        count = 0\r\n","        for fld in folders:\r\n","            index = folders.index(fld)\r\n","            print('Loading {} files (Index: {})'.format(fld, index))\r\n","            for root, dirs, files in os.walk(path + '\\\\' + fld, topdown=False):\r\n","                for file in files:\r\n","                    print(file)\r\n","                    if (file == '1.jpg'):\r\n","                        pass\r\n","                    else:\r\n","                        filepath = root + '\\\\' + file\r\n","                        detector = dlib.get_frontal_face_detector()\r\n","                        img = cv2.imread(filepath)\r\n","                        face = detector(img, 1)\r\n","                        for i, d in enumerate(face):\r\n","                            x1 = d.left()\r\n","                            y1 = d.top()\r\n","                            x2 = d.right()\r\n","                            y2 = d.bottom()\r\n","                            img = img[y1:y2, x1:x2]\r\n","                        lpath = 'D:\\\\NianXiang_File\\\\CNN\\\\Dataset\\\\small_dataset\\\\NEW'\r\n","                        filename = lpath + '\\\\' + str(index) + '\\\\' + str(count) + '.jpg'\r\n","                        cv2.imwrite(filename, img)\r\n","                        try:\r\n","                            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\r\n","                            resized = cv2.resize(img, (224, 224), cv2.INTER_LANCZOS4)\r\n","                            y.append(index)\r\n","                            x.append(resized)\r\n","                            count = count + 1\r\n","                        except:\r\n","                            pass\r\n","\r\n","                            # file = Data.static_load_image(ffile)\r\n","        np.save('{}_X.npy'.format(file_name), x)\r\n","        np.save('{}_Y.npy'.format(file_name), y)\r\n","        print(\"Complete\")\r\n","\r\n","class Evaluate(object):\r\n","    # 評估模型準確率\r\n","    @classmethod\r\n","    def evaluate(self, model, x=None, y=None):\r\n","        loss, score = model.evaluate(x=x, y=y, batch_size=16, verbose=2)\r\n","        print(\"Accuracy：{:.2f}%\".format(score * 100))\r\n","    # 預測資料\r\n","    @classmethod\r\n","    def predict(self, model=None, x=None):\r\n","        predict = model.predict(x=x, batch_size=16, verbose=2)\r\n","        return predict\r\n","    # 混淆矩陣\r\n","    @classmethod\r\n","    def confusion_matrix(self, model=None, normalize=False, title='Confusion Matrix', cls='le', x=None, y=None):\r\n","        predict = model.predict(x=x, batch_size=16, verbose=2)\r\n","        pred = np.argmax(predict, axis=1)\r\n","        print(np.unique(np.argmax(y, axis=1)), np.unique(pred))\r\n","        cnf_matrix = confusion_matrix(np.argmax(y, axis=1), pred)\r\n","        np.set_printoptions(precision=2)\r\n","        plt.figure()\r\n","        if cls == 'be':\r\n","            class_name = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\r\n","        if cls == 'le':\r\n","            class_name = [\"Frustration\", \"Confused\", \"Bored\", \"Delightful\", \"Flow\", \"Surprise\"]\r\n","        Evaluate.__plot_confusion_matrix(cnf_matrix, classes=class_name,\r\n","                                title=title,\r\n","                                normalize=normalize)\r\n","        plt.show()\r\n","\r\n","    @classmethod\r\n","    def __plot_confusion_matrix(self, cm, classes,\r\n","                                normalize=False,\r\n","                                title='Confusion matrix',\r\n","                                cmap=plt.cm.Blues):\r\n","        \"\"\"\r\n","        This function prints and plots the confusion matrix.\r\n","        Normalization can be applied by setting `normalize=True`.\r\n","        \"\"\"\r\n","        if normalize:\r\n","            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\r\n","            print(\"Normalized confusion matrix\")\r\n","        else:\r\n","            print('Confusion matrix, without normalization')\r\n","        print(cm)\r\n","\r\n","        plt.imshow(cm, interpolation='nearest', cmap=cmap)\r\n","        plt.title(title)\r\n","        plt.colorbar()\r\n","        tick_marks = np.arange(len(classes))\r\n","        plt.xticks(tick_marks, classes, rotation=45)\r\n","        plt.yticks(tick_marks, classes)\r\n","\r\n","        fmt = '.2f' if normalize else 'd'\r\n","        thresh = cm.max() / 2.\r\n","        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\r\n","            plt.text(j, i, format(cm[i, j], fmt),\r\n","                     horizontalalignment=\"center\",\r\n","                     color=\"white\" if cm[i, j] > thresh else \"black\")\r\n","\r\n","        plt.tight_layout()\r\n","        plt.ylabel('True label')\r\n","        plt.xlabel('Predicted label')"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LpnuSRydkaAG"},"source":["**Train.py 訓練器**"]},{"cell_type":"code","metadata":{"id":"rRXx-QBIkcJj","executionInfo":{"status":"ok","timestamp":1611800121739,"user_tz":-480,"elapsed":5308,"user":{"displayName":"吳貞宜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIOzgYhbporG1Eax-zD0HNdC2UZr8CRTfHsZcY5g=s64","userId":"00889427696288622203"}}},"source":["from keras import backend as K\r\n","from keras.layers.normalization import BatchNormalization\r\n","from keras.layers import Flatten, concatenate, Input, Dropout, Dense, Activation, MaxPooling2D, Conv2D, \\\r\n","    AveragePooling2D, GlobalAveragePooling2D, LSTM, TimeDistributed, merge, LeakyReLU\r\n","from keras import optimizers\r\n","from keras.regularizers import l2\r\n","from keras.models import Model, load_model\r\n","from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\r\n","from keras.utils import np_utils, plot_model, get_custom_objects\r\n","from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\r\n","from sklearn.utils import shuffle, class_weight\r\n","from sklearn.model_selection import StratifiedKFold, train_test_split, KFold, cross_val_score\r\n","from sklearn.metrics import classification_report, confusion_matrix\r\n","import gc\r\n","import itertools\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import pandas as pd\r\n","from sklearn.preprocessing import StandardScaler\r\n","# from Package.Data import Data, DataType\r\n","from sklearn.neighbors import KNeighborsClassifier\r\n","\r\n","## 訓練器\r\n","class Trainer(object):\r\n","    def __init__(self, img_width=224, img_height=224, num_classes=7, epochs=50, batch_size=96, data=Data, model=None):\r\n","        self.img_height = img_height\r\n","        self.img_width = img_width\r\n","        self.num_classes = num_classes\r\n","        self.epochs = epochs\r\n","        self.batch_size = batch_size\r\n","        self.set_model(model)\r\n","        self.data = data\r\n","    # 設定模型\r\n","    def set_model(self, model):\r\n","        self._model = model\r\n","\r\n","    # 取得模型\r\n","    def get_model(self):\r\n","        return self._model\r\n","\r\n","    # 訓練模型\r\n","    def fit(self, argument_amount=5, per_epoch_amount=220, filename=\"model\", use_steps=False):\r\n","        if (use_steps):\r\n","            history = self._model.fit_generator(self.data.generator(batch_size=self.batch_size),\r\n","                                                epochs=self.epochs,\r\n","                                                #  steps_per_epoch=int(np.ceil(train_x.shape[0] / float(self.batch_size))),\r\n","                                                workers=4,\r\n","                                                # shuffle=False,\r\n","                                                samples_per_epoch=(len(self.data.train_x) * argument_amount),\r\n","                                                initial_epoch=0,\r\n","                                                validation_data=(self.data.val_x, self.data.val_y),\r\n","                                                # validation_steps=self.batch_size,\r\n","                                                callbacks=self.callbacks,\r\n","                                                verbose=1,\r\n","                                                # class_weight=self.class_weight\r\n","                                                )\r\n","        else:\r\n","            history = self._model.fit_generator(self.data.generator(batch_size=self.batch_size),\r\n","                                                epochs=self.epochs,\r\n","                                                steps_per_epoch=per_epoch_amount,\r\n","                                                #  steps_per_epoch=int(np.ceil(train_x.shape[0] / float(self.batch_size))),\r\n","                                                workers=4,\r\n","                                                # shuffle=False,\r\n","                                                initial_epoch=0,\r\n","                                                validation_data=(self.data.val_x, self.data.val_y),\r\n","                                                # validation_steps=self.batch_size,\r\n","                                                callbacks=self.callbacks,\r\n","                                                verbose=1,\r\n","                                                # class_weight=self.class_weight\r\n","                                                )\r\n","        pd.DataFrame(history.history).to_csv('{}_history.csv'.format(filename))\r\n","    # 建立檢查點與Early Stopping\r\n","    def set_callbacks(self, filename,\r\n","                      check_point=ModelCheckpoint(\"callbacks.{epoch:02d}-{val_acc:.5f}.hdf5\", monitor='val_acc',\r\n","                                         verbose=1,\r\n","                                         save_best_only=True, mode='max'),\r\n","                      earlyStopping=EarlyStopping(monitor='val_acc', min_delta=0.001, patience=10, verbose=2, mode='max'),\r\n","                      reduce_lr=ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_lr=1E-9)):\r\n","        origin_list = [check_point, earlyStopping, reduce_lr]\r\n","        callbacks = []\r\n","        for item in origin_list:\r\n","            if item is not None:\r\n","                callbacks.append(item)\r\n","        self.callbacks = callbacks"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_Y-mxx0OnUEu"},"source":["Model.py 模型"]},{"cell_type":"code","metadata":{"id":"InjuAqIZnWVi","executionInfo":{"status":"ok","timestamp":1611800122137,"user_tz":-480,"elapsed":5703,"user":{"displayName":"吳貞宜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIOzgYhbporG1Eax-zD0HNdC2UZr8CRTfHsZcY5g=s64","userId":"00889427696288622203"}}},"source":["from keras import backend as K\r\n","from keras.layers.normalization import BatchNormalization\r\n","from keras.layers import Flatten, concatenate, Input, Dropout, Dense, Activation, MaxPooling2D, Conv2D, \\\r\n","    AveragePooling2D, GlobalAveragePooling2D, LSTM, TimeDistributed, merge, LeakyReLU\r\n","from keras import optimizers\r\n","from keras.regularizers import l2\r\n","from keras.models import Model, load_model\r\n","from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\r\n","from keras.utils import np_utils, plot_model, get_custom_objects\r\n","from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\r\n","from sklearn.utils import shuffle, class_weight\r\n","from sklearn.model_selection import StratifiedKFold, train_test_split, KFold\r\n","from sklearn.metrics import classification_report, confusion_matrix\r\n","import gc\r\n","import itertools\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import pandas as pd\r\n","from sklearn.preprocessing import StandardScaler\r\n","\r\n","\r\n","def swish(x):\r\n","    return K.sigmoid(x) * x\r\n","\r\n","\r\n","class Swish(Activation):\r\n","    def __init__(self, activation, **kwargs):\r\n","        super(Swish, self).__init__(activation, **kwargs)\r\n","        self.__name__ = 'swish'\r\n","\r\n","\r\n","get_custom_objects().update({\"swish\": Swish(swish)})\r\n","\r\n","\r\n","# 模型類別\r\n","class CustomModel(object):\r\n","    # 卷積層 + Batch Normalization Layer + Activate Function\r\n","    def conv2d_bn(self, x, filters, num_row, num_col, padding='same', strides=(1, 1), name=None,\r\n","                  activate='relu'):\r\n","        if name is not None:\r\n","            bn_name = name + '_bn'\r\n","            conv_name = name + '_conv'\r\n","        else:\r\n","            bn_name = None\r\n","            conv_name = None\r\n","        x = Conv2D(\r\n","            filters, (num_row, num_col),\r\n","            strides=strides,\r\n","            padding=padding,\r\n","            use_bias=False,\r\n","            kernel_initializer='he_normal',  # globor_uniform,\r\n","            kernel_regularizer = l2(0.0001),\r\n","            name = conv_name)(x)\r\n","        x = BatchNormalization(scale=True, name=bn_name)(x)\r\n","        if (activate != None):\r\n","            x = Activation(activate, name=name)(x)\r\n","        return x\r\n","\r\n","    # 激活模型\r\n","    def model_compile(self, loss='categorical_crossentropy', opt='adamax', met=['acc']):\r\n","        self._model.compile(loss=loss, optimizer=opt, metrics=met)\r\n","\r\n","    # 取得模型\r\n","    def get_model(self):\r\n","        return self._model\r\n","\r\n","    # 設定模型\r\n","    def set_model(self, model):\r\n","        self._model = model\r\n","\r\n","    # 遷移學習\r\n","    def transfer_learning(self, model):\r\n","        model.layers.pop()\r\n","        model.layers.pop()\r\n","        x = model.layers[-1].output\r\n","        x = Dense(7, activation='softmax', name='probbb')(x)#訓練時要改，基本為7，學習為6\r\n","        new_model = Model(inputs=model.input, outputs=x)\r\n","        self._model = new_model\r\n","\r\n","# 論文中提出之架構\r\n","class Dense_FaceLiveNet(CustomModel):\r\n","    def __init__(self, activate='swish', use_dense_block=True, use_global_average_pool=True):\r\n","        # 初始化\r\n","        #   Parameter\r\n","        #   1. activate                 : 激活函數\r\n","        #   2. use_dense_block          : 是否使用 Dense Block，若沒有使用，則為原本 FaceLiveNet 所使用之 Residual Block\r\n","        #   3. use_global_average_pool  : 是否使用 GlobalAveragePool，若沒有使用，則使用全連接層\r\n","        self.activate = activate\r\n","        self.use_dense_block = use_dense_block\r\n","        self.use_global_average_pool = use_global_average_pool\r\n","        self._model = self.build()\r\n","        self.model_compile()\r\n","\r\n","    # 建立模型架構\r\n","    def build(self):\r\n","        get_custom_objects().update({\"swish\": Swish(swish)})\r\n","        # Backend 為 Tensorflow 定義 channel axis 為 3\r\n","        channel_axis = 3\r\n","        # 定義 Input 的大小\r\n","        input_shape = Input(shape=(224, 224, 1), name='data')\r\n","\r\n","        # Stem layer\r\n","        net = self.conv2d_bn(input_shape, 32, 3, 3, strides=(2, 2), padding='valid', activate=self.activate)\r\n","        net = self.conv2d_bn(net, 32, 3, 3, strides=(1, 1), padding='valid', activate=self.activate)\r\n","        net = self.conv2d_bn(net, 64, 3, 3, strides=(1, 1), activate=self.activate)\r\n","        branch_0 = MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(net)\r\n","        net = self.conv2d_bn(branch_0, 80, 3, 3, strides=(2, 2), padding='valid', activate=self.activate)\r\n","        net = self.conv2d_bn(net, 192, 3, 3, strides=(1, 1), padding='valid', activate=self.activate)\r\n","        x = MaxPooling2D((3, 3), strides=(2, 2), padding=\"valid\")(net)\r\n","\r\n","        # inception1\r\n","        branch_0 = self.conv2d_bn(x, 96, 1, 1, strides=(1, 1), activate=self.activate)\r\n","        branch_1 = self.conv2d_bn(x, 64, 1, 1, strides=(1, 1), activate=self.activate)\r\n","        branch_1 = self.conv2d_bn(branch_1, 96, 3, 3, strides=(1, 1), activate=self.activate)\r\n","        branch_2 = self.conv2d_bn(x, 64, 1, 1, strides=(1, 1), activate=self.activate)\r\n","        branch_2 = self.conv2d_bn(branch_2, 96, 3, 3, strides=(1, 1), activate=self.activate)\r\n","        branch_2 = self.conv2d_bn(branch_2, 96, 3, 3, strides=(1, 1), activate=self.activate)\r\n","        x = [branch_0, branch_1, branch_2]\r\n","        mix1 = concatenate(x, axis=channel_axis)\r\n","        x = self.conv2d_bn(mix1, 96, 1, 1, strides=(1, 1), padding='valid', activate=self.activate)\r\n","\r\n","        # inception2\r\n","        branch_0 = self.conv2d_bn(x, 64, 3, 3, strides=(1, 1), activate=self.activate)\r\n","        branch_1 = self.conv2d_bn(x, 96, 1, 1, strides=(1, 1), activate=self.activate)\r\n","        branch_1 = self.conv2d_bn(branch_1, 128, 3, 3, strides=(1, 1), activate=self.activate)\r\n","        branch_1 = self.conv2d_bn(branch_1, 160, 3, 3, strides=(1, 1), activate=self.activate)\r\n","        branch_3 = AveragePooling2D((3, 3), strides=(1, 1), padding='same', name=\"avg_pool_1\")(x)\r\n","        if (self.use_dense_block):\r\n","            x1 = [x, branch_0, branch_1, branch_3]\r\n","        else:\r\n","            x1 = [branch_0, branch_1, branch_3]\r\n","        mix2 = concatenate(x1, axis=channel_axis)\r\n","\r\n","        # inception3\r\n","        branch_0 = self.conv2d_bn(mix2, 192, 1, 1, strides=(1, 1), activate=self.activate)\r\n","        branch_1 = self.conv2d_bn(mix2, 128, 1, 1, strides=(1, 1), activate=self.activate)\r\n","        branch_1 = self.conv2d_bn(branch_1, 160, 1, 7, strides=(1, 1), activate=self.activate)\r\n","        branch_1 = self.conv2d_bn(branch_1, 160, 7, 1, strides=(1, 1), activate=self.activate)\r\n","        if (self.use_dense_block):\r\n","            x = [x, mix2, branch_0, branch_1]\r\n","        else:\r\n","            x = [mix2, branch_0, branch_1]\r\n","        mix3 = concatenate(x, axis=channel_axis, name='mixed3')\r\n","\r\n","        # translate layer\r\n","        if (self.use_dense_block):\r\n","            x = self.conv2d_bn(mix3, 192, 1, 1, strides=(1, 1), padding='valid', activate=self.activate)\r\n","            x = AveragePooling2D((2, 2), strides=(2, 2))(x)\r\n","            x1 = BatchNormalization(scale=True, axis=channel_axis)(x)\r\n","        else:\r\n","            x1 = self.conv2d_bn(mix3, 192, 1, 1, strides=(1, 1), padding='valid', activate=self.activate)\r\n","\r\n","        # inception4\r\n","        netb00 = self.conv2d_bn(x1, 192, 1, 1, strides=(1, 1), padding='same', activate=self.activate)\r\n","        netb10 = self.conv2d_bn(x1, 192, 1, 1, strides=(1, 1), padding='same', activate=self.activate)\r\n","        netb11 = self.conv2d_bn(netb10, 256, 3, 3, strides=(1, 1), padding='same', activate=self.activate)\r\n","        netb20 = self.conv2d_bn(x1, 160, 1, 1, strides=(1, 1), padding='same', activate=self.activate)\r\n","        netb21 = self.conv2d_bn(netb20, 192, 3, 3, strides=(1, 1), padding='same', activate=self.activate)\r\n","        netb22 = self.conv2d_bn(netb21, 256, 3, 3, strides=(1, 1), padding='same', activate=self.activate)\r\n","        netb30 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x1)\r\n","        netb31 = self.conv2d_bn(netb30, 160, 1, 1, strides=(1, 1), padding='same', activate=self.activate)\r\n","        if (self.use_dense_block):\r\n","            x = concatenate([x, netb00, netb11, netb22, netb31], axis=channel_axis, name='mixed4')\r\n","        else:\r\n","            x = concatenate([netb00, netb11, netb22, netb31], axis=channel_axis, name='mixed4')\r\n","\r\n","        # inception5 * 2\r\n","        feature_list = [x]\r\n","        for _ in range(2):\r\n","            branch_0 = self.conv2d_bn(x, 256, 1, 1, strides=(1, 1), activate=self.activate)\r\n","            branch_1 = self.conv2d_bn(x, 128, 1, 3, strides=(1, 1), activate=self.activate)\r\n","            branch_1 = self.conv2d_bn(branch_1, 192, 3, 1, strides=(1, 1), activate=self.activate)\r\n","            branch_1 = self.conv2d_bn(branch_1, 256, 1, 3, strides=(1, 1), activate=self.activate)\r\n","            a = [branch_0, branch_1]\r\n","            mix5 = concatenate(a, axis=channel_axis)\r\n","            x1 = self.conv2d_bn(mix5, 256, 1, 1, strides=(1, 1), padding='valid', activate=self.activate)\r\n","            x = concatenate([x, x1], axis=channel_axis)\r\n","            feature_list.append(x)\r\n","        if (self.use_global_average_pool):\r\n","            x = concatenate(feature_list, axis=channel_axis)\r\n","\r\n","        if (self.use_global_average_pool):\r\n","            # GlobalAveragePooling Layer\r\n","            x = GlobalAveragePooling2D(name='global_avg_pool')(x)\r\n","        else:\r\n","            # Fully Connection Layer\r\n","            x = Dense(2000)(x)\r\n","            x = Dense(1000)(x)\r\n","        x = Dense(7, name='Logits')(x)\r\n","        x = Activation('softmax', name='probb')(x)\r\n","        model = Model(inputs=input_shape, outputs=x, name='ANet')\r\n","        return model"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"g9xMrhnAvysY","executionInfo":{"status":"ok","timestamp":1611800149650,"user_tz":-480,"elapsed":33214,"user":{"displayName":"吳貞宜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhIOzgYhbporG1Eax-zD0HNdC2UZr8CRTfHsZcY5g=s64","userId":"00889427696288622203"}},"outputId":"c90cb764-1708-4278-a47b-8c80e2a5d62f"},"source":["\r\n","if __name__ == '__main__':\r\n","    Data.load_train_data(filename=\"JAFFE\")\r\n","    ## 畫出混淆矩陣\r\n","    #   1. 指定模型\r\n","    model = load_model('/content/drive/MyDrive/basic_emotion/callbacks.01-0.90909.hdf5')\r\n","    model.summary()\r\n","    #   2. 資料前處理\r\n","    x = np.load('/content/drive/MyDrive/basic_emotion/JAFFE_test_x.npy')\r\n","    y = np.load('/content/drive/MyDrive/basic_emotion/JAFFE_test_y.npy')\r\n","    x = Data.static_arr_reshape(arr=x)\r\n","    # #   3. 呼叫方法畫出混淆矩陣\r\n","    Evaluate.confusion_matrix(model=model,\r\n","                          cls='be',\r\n","                          x=x,\r\n","                          y=y)\r\n","    # #   4. 評估模型準確率\r\n","    Evaluate.evaluate(model=model, x=x, y=y)\r\n","    #   5. 預測模型準確率\r\n","    # x = Data.static_arr_reshape(arr=np.load('D:\\\\NianXiang_File\\\\Research\\\\Dataset\\\\gaga_predict_x.npy'))\r\n","    # print(x.shape)\r\n","    # predict = Evaluate.predict(model=model, x=x)\r\n","    # np.save('gaga_predict_data.npy', predict)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Complete\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","data (InputLayer)               [(None, 224, 224, 1) 0                                            \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 111, 111, 32) 288         data[0][0]                       \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 111, 111, 32) 128         conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 111, 111, 32) 0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 109, 109, 32) 9216        activation_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 109, 109, 32) 128         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 109, 109, 32) 0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 109, 109, 64) 18432       activation_2[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 109, 109, 64) 256         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 109, 109, 64) 0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 54, 54, 64)   0           activation_3[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 26, 26, 80)   46080       max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 26, 26, 80)   320         conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 26, 26, 80)   0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 24, 24, 192)  138240      activation_4[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 24, 24, 192)  768         conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 24, 24, 192)  0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 11, 11, 192)  0           activation_5[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 11, 11, 64)   12288       max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 11, 11, 64)   256         conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 11, 11, 64)   0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 11, 11, 64)   12288       max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 11, 11, 96)   55296       activation_9[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 11, 11, 64)   256         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 11, 11, 96)   384         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 11, 11, 64)   0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 11, 11, 96)   0           batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 11, 11, 96)   18432       max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 11, 11, 96)   55296       activation_7[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 11, 11, 96)   82944       activation_10[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 11, 11, 96)   384         conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 11, 11, 96)   384         conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 11, 11, 96)   384         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 11, 11, 96)   0           batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 11, 11, 96)   0           batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 11, 11, 96)   0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 11, 11, 288)  0           activation_6[0][0]               \n","                                                                 activation_8[0][0]               \n","                                                                 activation_11[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 11, 11, 96)   27648       concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 11, 11, 96)   384         conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 11, 11, 96)   0           batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 11, 11, 96)   9216        activation_12[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 11, 11, 96)   384         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 11, 11, 96)   0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 11, 11, 128)  110592      activation_14[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 11, 11, 128)  512         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 11, 11, 128)  0           batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 11, 11, 64)   55296       activation_12[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 11, 11, 160)  184320      activation_15[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 11, 11, 64)   256         conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 11, 11, 160)  640         conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 11, 11, 64)   0           batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 11, 11, 160)  0           batch_normalization_16[0][0]     \n","__________________________________________________________________________________________________\n","avg_pool_1 (AveragePooling2D)   (None, 11, 11, 96)   0           activation_12[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 11, 11, 416)  0           activation_12[0][0]              \n","                                                                 activation_13[0][0]              \n","                                                                 activation_16[0][0]              \n","                                                                 avg_pool_1[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 11, 11, 128)  53248       concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 11, 11, 128)  512         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 11, 11, 128)  0           batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 11, 11, 160)  143360      activation_18[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 11, 11, 160)  640         conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 11, 11, 160)  0           batch_normalization_19[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 11, 11, 192)  79872       concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 11, 11, 160)  179200      activation_19[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 11, 11, 192)  768         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 11, 11, 160)  640         conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 11, 11, 192)  0           batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 11, 11, 160)  0           batch_normalization_20[0][0]     \n","__________________________________________________________________________________________________\n","mixed3 (Concatenate)            (None, 11, 11, 864)  0           activation_12[0][0]              \n","                                                                 concatenate_2[0][0]              \n","                                                                 activation_17[0][0]              \n","                                                                 activation_20[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 11, 11, 192)  165888      mixed3[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 11, 11, 192)  768         conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 11, 11, 192)  0           batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","average_pooling2d_1 (AveragePoo (None, 5, 5, 192)    0           activation_21[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 5, 5, 192)    768         average_pooling2d_1[0][0]        \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 5, 5, 160)    30720       batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 5, 5, 160)    640         conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 5, 5, 160)    0           batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 5, 5, 192)    36864       batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 5, 5, 192)    276480      activation_25[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 5, 5, 192)    768         conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 5, 5, 192)    768         conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 5, 5, 192)    0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 5, 5, 192)    0           batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","average_pooling2d_2 (AveragePoo (None, 5, 5, 192)    0           batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 5, 5, 192)    36864       batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 5, 5, 256)    442368      activation_23[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 5, 5, 256)    442368      activation_26[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 5, 5, 160)    30720       average_pooling2d_2[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 5, 5, 192)    768         conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 5, 5, 256)    1024        conv2d_24[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 5, 5, 256)    1024        conv2d_27[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 5, 5, 160)    640         conv2d_28[0][0]                  \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 5, 5, 192)    0           batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 5, 5, 256)    0           batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","activation_27 (Activation)      (None, 5, 5, 256)    0           batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","activation_28 (Activation)      (None, 5, 5, 160)    0           batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","mixed4 (Concatenate)            (None, 5, 5, 1056)   0           average_pooling2d_1[0][0]        \n","                                                                 activation_22[0][0]              \n","                                                                 activation_24[0][0]              \n","                                                                 activation_27[0][0]              \n","                                                                 activation_28[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 5, 5, 128)    405504      mixed4[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_31 (BatchNo (None, 5, 5, 128)    512         conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","activation_30 (Activation)      (None, 5, 5, 128)    0           batch_normalization_31[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 5, 5, 192)    73728       activation_30[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_32 (BatchNo (None, 5, 5, 192)    768         conv2d_31[0][0]                  \n","__________________________________________________________________________________________________\n","activation_31 (Activation)      (None, 5, 5, 192)    0           batch_normalization_32[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 5, 5, 256)    270336      mixed4[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 5, 5, 256)    147456      activation_31[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 5, 5, 256)    1024        conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_33 (BatchNo (None, 5, 5, 256)    1024        conv2d_32[0][0]                  \n","__________________________________________________________________________________________________\n","activation_29 (Activation)      (None, 5, 5, 256)    0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","activation_32 (Activation)      (None, 5, 5, 256)    0           batch_normalization_33[0][0]     \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 5, 5, 512)    0           activation_29[0][0]              \n","                                                                 activation_32[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 5, 5, 256)    131072      concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_34 (BatchNo (None, 5, 5, 256)    1024        conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","activation_33 (Activation)      (None, 5, 5, 256)    0           batch_normalization_34[0][0]     \n","__________________________________________________________________________________________________\n","concatenate_4 (Concatenate)     (None, 5, 5, 1312)   0           mixed4[0][0]                     \n","                                                                 activation_33[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 5, 5, 128)    503808      concatenate_4[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_36 (BatchNo (None, 5, 5, 128)    512         conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","activation_35 (Activation)      (None, 5, 5, 128)    0           batch_normalization_36[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 5, 5, 192)    73728       activation_35[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_37 (BatchNo (None, 5, 5, 192)    768         conv2d_36[0][0]                  \n","__________________________________________________________________________________________________\n","activation_36 (Activation)      (None, 5, 5, 192)    0           batch_normalization_37[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 5, 5, 256)    335872      concatenate_4[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_37 (Conv2D)              (None, 5, 5, 256)    147456      activation_36[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_35 (BatchNo (None, 5, 5, 256)    1024        conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_38 (BatchNo (None, 5, 5, 256)    1024        conv2d_37[0][0]                  \n","__________________________________________________________________________________________________\n","activation_34 (Activation)      (None, 5, 5, 256)    0           batch_normalization_35[0][0]     \n","__________________________________________________________________________________________________\n","activation_37 (Activation)      (None, 5, 5, 256)    0           batch_normalization_38[0][0]     \n","__________________________________________________________________________________________________\n","concatenate_5 (Concatenate)     (None, 5, 5, 512)    0           activation_34[0][0]              \n","                                                                 activation_37[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_38 (Conv2D)              (None, 5, 5, 256)    131072      concatenate_5[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_39 (BatchNo (None, 5, 5, 256)    1024        conv2d_38[0][0]                  \n","__________________________________________________________________________________________________\n","activation_38 (Activation)      (None, 5, 5, 256)    0           batch_normalization_39[0][0]     \n","__________________________________________________________________________________________________\n","concatenate_6 (Concatenate)     (None, 5, 5, 1568)   0           concatenate_4[0][0]              \n","                                                                 activation_38[0][0]              \n","__________________________________________________________________________________________________\n","concatenate_7 (Concatenate)     (None, 5, 5, 3936)   0           mixed4[0][0]                     \n","                                                                 concatenate_4[0][0]              \n","                                                                 concatenate_6[0][0]              \n","__________________________________________________________________________________________________\n","global_avg_pool (GlobalAverageP (None, 3936)         0           concatenate_7[0][0]              \n","__________________________________________________________________________________________________\n","prob (Dense)                    (None, 7)            27559       global_avg_pool[0][0]            \n","==================================================================================================\n","Total params: 5,025,671\n","Trainable params: 5,013,543\n","Non-trainable params: 12,128\n","__________________________________________________________________________________________________\n","3/3 - 2s\n","[0 1 2 3 4 5 6] [0 1 2 3 4 5 6]\n","Confusion matrix, without normalization\n","[[6 0 0 0 0 0 0]\n"," [0 5 0 0 0 0 0]\n"," [0 0 4 0 0 0 0]\n"," [0 0 0 5 0 1 0]\n"," [0 0 0 0 6 0 0]\n"," [0 0 0 0 0 7 0]\n"," [0 0 0 0 0 0 9]]\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["3/3 - 2s - loss: 0.2346 - acc: 0.9767\n","Accuracy：97.67%\n"],"name":"stdout"}]}]}